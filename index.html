<!DOCTYPE html>
<html>

<head>
  <meta charset="utf-8">
  <meta name="description"
    content="Deformable Neural Radiance Fields creates free-viewpoint portraits (nerfies) from casually captured videos.">
  <meta name="keywords" content="Nerfies, D-NeRF, NeRF">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <!-- Google tag (gtag.js) -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-SN3V1V2CRF"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());
  
    gtag('config', 'G-SN3V1V2CRF');
  </script>
  <title>Objects Count Optimization for Text-to-image Diffusion Models</title>


  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/favicon.svg">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>

<body>
  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">Objects Count Optimization for Text-to-image Diffusion Models</h1>
            <div class="is-size-5 publication-authors">
              <span class="author-block">
                <a href="https://github.com/ozzafar">Oz Zafar</a>,
              </span>
              <span class="author-block">
                <a href="https://idansc.github.io/">Idan Schwartz</a>,
              </span>
              <span class="author-block">
                <a href="http://www.cs.tau.ac.il/~wolf/">Lior Wolf</a>
              </span>
            </div>

            <div class="is-size-5 publication-authors">
              <span class="author-block"><sup>*</sup>Equal contribution</span>
              <span class="author-block">Tel Aviv University,</span>
            </div>

            <div class="column has-text-centered">
              <div class="publication-links">
                <!-- PDF Link. -->
                <span class="link-block">
                  <a href="TODO"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                    </span>
                    <span>Paper</span>
                  </a>
                </span>
                <span class="link-block">
                  <a href="TODO" class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="ai ai-arxiv"></i>
                    </span>
                    <span>arXiv</span>
                  </a>
                </span>
                <!-- Code Link. -->
                <span class="link-block">
                  <a href="https://github.com/ozzafar/discriminative_class_tokens_for_counting"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span>
              </div>

            </div>
          </div>
        </div>
      </div>
    </div>
  </section>

  <section class="hero teaser">
    <div class="container is-max-desktop">
      <img src="./static/images/teas.png" alt="Teaser" class="teaser-image">
      <h2 class="subtitle has-text-centered">
        Our method corrects the output from generative text to image models with respect to a pre-trained classifer.
      </h2>
    </div>
    </div>
  </section>



  <section class="section">
    <div class="container is-max-desktop">
      <!-- Abstract. -->
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">Abstract</h2>
          <div class="content has-text-justified">

            <p>We address a persistent challenge in text-to-image models: accurately generating a specified number of objects.
               Current models, which learn from image-text pairs, inherently struggle with counting as training data cannot depict every possible number of objects for any given object.
               To solve this, we propose optimizing the generated image based on a counting loss derived from a counting model that aggregates an object's matcher potentials.
               Employing an out-of-the-box counting model is challenging for two reasons: (i) the model requires a scaling hyperparameter for the potential aggregation that varies depending on the viewpoint of the objects, and (ii) classifier guidance techniques require models that operate on noisy images.
               To this end, our optimization is done on inference time, iteratively by conditioning on inferred images.
               Altering the text conditioning embedding and generating an image. Our method offers three key advantages: (i) it is a zero-shot method requiring no additional training data; (ii) it is a plug-and-play solution facilitating rapid changes to the counting techniques and image generation methods; and (iii) it provides user control for the desired level of accuracy.
               We evaluate the generation of various objects and demonstrate that our approach significantly enhances accuracy.
            </p>
          </div>
        </div>
      </div>
      <!--/ Abstract. -->
    </div>
  </section>


  <section class="section">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column is-full-width">
          <h2 class="title is-2">Iterations</h2>
          <div class="content has-text-justified">
            <p>
              We can show how the generated image changes over time as the embedding is modified iteratively.
            </p>
          </div>
          <div class="columns is-vcentered interpolation-panel">
            <div class="column is-3 has-text-centered">
              <img src="./static/gifs/oranges.gif" class="interpolation-image"
                alt="Interpolate start reference image." />
              <p>5 oranges</p>
            </div>
            <div class="column is-3 has-text-centered">
              <img src="./static/gifs/cupcakes.gif" class="interpolation-image"
                alt="Interpolate start reference image." />
              <p>5 cupcakes</p>
            </div>
            <div class="column is-3 has-text-centered">
              <img src="./static/gifs/cars.gif" class="interpolation-image"
                alt="Interpolate start reference image." />
              <p>5 cars</p>
            </div>
            <div class="column is-3 has-text-centered">
              <img src="./static/gifs/sheep.gif" class="interpolation-image"
                alt="Interpolate start reference image." />
              <p>5 sheep</p>
            </div>

          </div>
          <br />

          <h2 class="title is-2">Examples with context</h2>
          <div class="content has-text-justified">
            <p>
              The class tokens trained with our method can also be used in different context, as shown in the images
              below.
              The three classes are from ImageNet, they are <i>tiger cat</i>, <i>japanese spaniel</i>, and <i>beach
                wagon</i>.
            </p>
          </div>
          <div class="content has-text-centered">
            <img src="static/images/context.png">
          </div>

          <h2 class="title is-2">Method</h2>
          <div class="content has-text-justified">
            <p>
              Our method works by adding a single new token to the input vocabulary of a text-to-image model. This token
              is then updated
              using a signal from a pretrained classifier. The classifier is used to guide the generation of
              images. Using gradient skipping, we more effectively update the embedding of the new token. We show that it
              is sufficient to backpropagate through the top iteration of the diffusion process.
            </p>
          </div>
          <div class="content has-text-centered">
            <img width="500px" src="static/images/training.png">
          </div>



          <h2 class="title is-2">Optimization process</h2>
          <div class="content has-text-justified">
            <p>
              Methods such as <i>textual inversion</i> (TI) rely on tuning a token using a few images.
              Relying on a pre-trained classifier allows the token to capture a broader distribution, corresponding
              to a class, as opposed to specific features of the individuals in the given images. As seen below, TI-generated images often lack diversity and are prone to incorporating background features from a limited set of images. For reference, we also display SD's generated samples.
              <br />
              <b>Lack of diversity</b> In the Japanese spaniel class, TI generates a black-and-white dog due to limited colors in the images, causing "A statue of a Japanese spaniel" prompts to lose the statue texture.
              <br />
              <b>Biased background</b>  In the beach wagon class, TI merges the road into the object, transforming both the car and the background from beach to road.
            </p>
          </div>
          <div class="content has-text-centered">
            <img src="static/images/optimization_process.png">
          </div>

          <h2 class="title is-2"> Class transfer </h2>
          <div class="content has-text-justified">
            <p>
              Our method has the ability to inverse the action of a classifier without access to its trained data. For example, we often observe changes in the background when optimizing for an object's class. Applying our method with ImageNet-trained classifier results in an image of a lobster on a plate given the phrase `American lobster.'
              Another example is the `horizontal bar' class, for which our method predominantly generates images containing athletes and a gym environment. We manually assessed ImageNet's training data by classifying 100 images from the `American lobster' and `horizontal bar' classes and determining whether they exhibit these features in the training data.
              For the `American lobster' class, 55% of the images featured a plate and the lobster in an edible form, and for the `horizontal bar' class, 95% of the images included an athlete performer.
            </p>
          </div>
          <div class="content has-text-centered">
            <img src="static/images/class_transfer.png">
          </div>
        
        </div>
      </div>


    </div>
  </section>


  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <pre><code> TODO </code></pre>
    </div>
  </section>


  <footer class="footer">
    <div class="container">
      <div class="content has-text-centered">
        <a class="icon-link" href="https://arxiv.org/pdf/2303.17155.pdf">
          <i class="fas fa-file-pdf"></i>
        </a>
        <a class="icon-link" href="https://github.com/idansc/discriminative_class_tokens" class="external-link"
          disabled>
          <i class="fab fa-github"></i>
        </a>
      </div>
      <div class="columns is-centered">
        <div class="column is-8">
          <div class="content">
            <p>
              This website is licensed under a <a rel="license"
                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
                Commons Attribution-ShareAlike 4.0 International License</a>.
            </p>
            <p>
              This means you are free to borrow the <a href="https://github.com/vesteinn/disco">source
                code</a> of this website, we just ask that you link back to this page in the footer.
              The code is based on <a
                href="https://github.com/nerfies/nerfies.github.io">https://github.com/nerfies/nerfies.github.io</a>.
              Please remember to remove the analytics code included in the header of the website which
              you do not want on your website.
            </p>
          </div>
        </div>
      </div>
    </div>
  </footer>

</body>

</html>
